- Sensitivity analysis on the omniglot one-shot classification task:

  - 

    <img src="/Users/wangchong/Documents/000/papers/STDP/figures/sensitivity.png" style='zoom:40%'/>

   - i and j are indices of timestep. During each task, the RNN is given input a concatenation of a image (preprocessed by a CNN) and a one-hot label. In each episode, the network is presented with images of twenty different symbols, each associated with a random category. Each pair is repeated 4 time steps. At the end, the network is presented with a new "query" image that is the same category as one of the twenty images, and should output the label associated with that image.

   - There are two places where the heatmap is dark (i.e. the norm of Jacobian between those timesteps is large). On the diagonal, gradient between closeby time steps is large. On the top of the image, which show the gradient of the output *after the  query image is presented* with respect to early timesteps. There is a dark spot at the timesteps where the associated image is presented.

- In a simulation of dynamic two-armed bandit task using T-maze, the modulatory signal for plasticity generated by a trained network is significantly correlated with a wide range of behavioral variables, and the variables that correlate it varies between different stages of the task.

  - | Location | intercept              | prev_outcome           | prev_choice            | choice_X_outcome       | q_prev_c               | rpe                        | upcoming_choice        | q_upcoming_choice      | qsum                   | qdiff                  |
| -------- | ---------------------- | ---------------------- | ---------------------- | ---------------------- | ---------------------- | -------------------------- | ---------------------- | ---------------------- | ---------------------- | ---------------------- |
| (1, 2)   | -3.63 ± 0.04 (p=0.000) | -1.28 ± 0.08 (p=0.000) | 0.20 ± 0.05 (p=0.000)  | 1.11 ± 0.13 (p=0.000)  | -0.45 ± 0.05 (p=0.000) | **-0.83 ± 0.03 (p=0.000)** | 0.03 ± 0.05 (p=0.272)  | 0.62 ± 0.12 (p=0.000)  | 0.12 ± 0.10 (p=0.012)  | -0.16 ± 0.07 (p=0.000) |
| (1, 1)   | -3.14 ± 0.08 (p=0.000) | -0.01 ± 0.16 (p=0.931) | 0.05 ± 0.09 (p=0.320)  | -1.80 ± 0.26 (p=0.000) | 0.31 ± 0.11 (p=0.000)  | **-0.32 ± 0.07 (p=0.000)** | 0.01 ± 0.09 (p=0.859)  | -0.01 ± 0.25 (p=0.960) | 0.16 ± 0.19 (p=0.111)  | 0.73 ± 0.15 (p=0.000)  |
| (2, 1)   | -1.45 ± 0.10 (p=0.000) | -0.22 ± 0.20 (p=0.025) | 1.06 ± 0.12 (p=0.000)  | -0.29 ± 0.32 (p=0.077) | 0.16 ± 0.13 (p=0.015)  | **-0.39 ± 0.08 (p=0.000)** | -0.29 ± 0.11 (p=0.000) | 0.20 ± 0.30 (p=0.189)  | -0.16 ± 0.24 (p=0.191) | 0.33 ± 0.18 (p=0.000)  |
| (3, 1)   | -1.23 ± 0.09 (p=0.000) | -0.13 ± 0.17 (p=0.113) | 0.69 ± 0.10 (p=0.000)  | 0.15 ± 0.27 (p=0.278)  | 0.15 ± 0.11 (p=0.008)  | **-0.29 ± 0.07 (p=0.000)** | -0.37 ± 0.10 (p=0.000) | 0.19 ± 0.26 (p=0.145)  | -0.18 ± 0.20 (p=0.081) | 0.11 ± 0.15 (p=0.155)  |
| (4, 1)   | -3.81 ± 0.09 (p=0.000) | 0.17 ± 0.18 (p=0.065)  | 2.75 ± 0.10 (p=0.000)  | -0.12 ± 0.29 (p=0.421) | 0.37 ± 0.12 (p=0.000)  | **-0.20 ± 0.07 (p=0.000)** | -0.54 ± 0.10 (p=0.000) | 0.10 ± 0.27 (p=0.449)  | -0.16 ± 0.21 (p=0.151) | 0.23 ± 0.16 (p=0.007)  |
| (4, 2)   | -2.74 ± 0.11 (p=0.000) | 0.43 ± 0.20 (p=0.000)  | 1.19 ± 0.12 (p=0.000)  | -0.73 ± 0.34 (p=0.000) | 0.40 ± 0.14 (p=0.000)  | 0.04 ± 0.08 (p=0.363)      | -0.76 ± 0.12 (p=0.000) | -0.20 ± 0.31 (p=0.216) | 0.08 ± 0.25 (p=0.549)  | 0.32 ± 0.19 (p=0.001)  |
| (4, 3)   | -2.90 ± 0.12 (p=0.000) | 0.38 ± 0.22 (p=0.001)  | 1.91 ± 0.13 (p=0.000)  | -0.75 ± 0.36 (p=0.000) | 0.21 ± 0.15 (p=0.006)  | 0.17 ± 0.09 (p=0.000)      | -0.46 ± 0.13 (p=0.000) | -0.79 ± 0.34 (p=0.000) | 0.29 ± 0.27 (p=0.031)  | 0.41 ± 0.20 (p=0.000)  |
| (3, 3)   | -1.45 ± 0.08 (p=0.000) | 0.02 ± 0.14 (p=0.752)  | 0.57 ± 0.08 (p=0.000)  | -0.07 ± 0.22 (p=0.520) | -0.02 ± 0.10 (p=0.743) | 0.04 ± 0.06 (p=0.192)      | 0.35 ± 0.08 (p=0.000)  | -0.59 ± 0.21 (p=0.000) | 0.21 ± 0.16 (p=0.011)  | 0.20 ± 0.13 (p=0.002)  |
| (2, 3)   | -1.13 ± 0.08 (p=0.000) | -0.11 ± 0.15 (p=0.159) | 0.33 ± 0.09 (p=0.000)  | 0.19 ± 0.24 (p=0.124)  | -0.04 ± 0.10 (p=0.434) | -0.07 ± 0.06 (p=0.032)     | 0.41 ± 0.09 (p=0.000)  | -0.62 ± 0.24 (p=0.000) | 0.30 ± 0.18 (p=0.001)  | 0.26 ± 0.14 (p=0.000)  |
| (1, 3)   | -4.87 ± 0.10 (p=0.000) | 0.10 ± 0.18 (p=0.301)  | -0.06 ± 0.11 (p=0.299) | 0.53 ± 0.29 (p=0.000)  | 0.07 ± 0.12 (p=0.289)  | 0.03 ± 0.07 (p=0.439)      | 0.76 ± 0.10 (p=0.000)  | -0.69 ± 0.28 (p=0.000) | 0.24 ± 0.21 (p=0.024)  | 0.11 ± 0.16 (p=0.177)  |

  
  - The location column above indexes the 2d array below.
    - $$
      1\ 1\ 1\ 1\ 1\ 1\ 1 \\
      1\ 0\ 0\ 0\ 0\ 0\ 1 \\
      1\ 0\ 1\ 0\ 1\ 0\ 1 \\
      1\ 0\ 1\ 0\ 1\ 0\ 1 \\
      1\ 0\ 0\ 0\ 0\ 0\ 1 \\
      1\ 1\ 1\ 1\ 1\ 1\ 1 \\
      $$

  - For the maze task, I fit a linear regression model from behavioral variables to the modulation activity at each location in the maze. The results show that the modulatory activity is significantly modulated by behaviorally relevant variables. 

  - Specifically, right after the target is reached, the modulation signal is *negatively* correlated with the reward prediction error. At different locations the signal is also correlated with a diverse set of other variables.

